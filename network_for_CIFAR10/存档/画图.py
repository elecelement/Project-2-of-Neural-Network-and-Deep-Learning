import matplotlib.pyplot as plt
import numpy as np

# Data for the 5 files
loss_data = [
    [1.72, 1.36, 1.22, 1.11, 1.03, 0.962, 0.919, 0.88, 0.85, 0.819, 0.798, 0.777, 0.762, 0.744, 0.727, 0.715, 0.701, 0.689, 0.676, 0.669, 0.652, 0.647, 0.64, 0.633, 0.627],
    [1.69, 1.4, 1.28, 1.2, 1.11, 1.05, 0.996, 0.959, 0.924, 0.893, 0.877, 0.854, 0.834, 0.819, 0.798, 0.791, 0.777, 0.762, 0.751, 0.74, 0.731, 0.725, 0.716, 0.705, 0.697],
    [1.75, 1.43, 1.29, 1.2, 1.12, 1.05, 0.956, 0.921, 0.887, 0.861, 0.84, 0.824, 0.802, 0.788, 0.772, 0.755, 0.743, 0.731, 0.722, 0.706, 0.695, 0.683, 0.672, 0.666],
    [1.82, 1.47, 1.33, 1.23, 1.16, 1.08, 1.02, 0.977, 0.935, 0.906, 0.869, 0.848, 0.825, 0.801, 0.784, 0.768, 0.755, 0.735, 0.72, 0.706, 0.697, 0.677, 0.672, 0.659, 0.65],
    [1.92, 1.45, 1.26, 1.13, 1.02, 1.02, 0.964, 0.917, 0.876, 0.841, 0.815, 0.796, 0.767, 0.75, 0.735, 0.725, 0.705, 0.699, 0.685, 0.673, 0.664, 0.652, 0.644, 0.638, 0.63]
]
loss_data_new = [
    [1.75, 1.38, 1.23, 1.11, 1.02, 0.957, 0.919, 0.874, 0.848, 0.818, 0.796, 0.773, 0.756, 0.739, 0.722, 0.71, 0.699, 0.684, 0.672, 0.663, 0.655, 0.64, 0.636, 0.629, 0.618],
    [1.75, 1.39, 1.23, 1.12, 1.04, 0.979, 0.932, 0.895, 0.865, 0.837, 0.814, 0.791, 0.776, 0.757, 0.737, 0.725, 0.713, 0.7, 0.694, 0.682, 0.666, 0.66, 0.652, 0.647, 0.636],
    [1.72, 1.36, 1.22, 1.11, 1.03, 0.962, 0.919, 0.88, 0.85, 0.819, 0.798, 0.777, 0.762, 0.744, 0.727, 0.715, 0.701, 0.689, 0.676, 0.669, 0.652, 0.647, 0.64, 0.633, 0.627]
]
loss_data_additional = [
    [1.75, 1.38, 1.23, 1.12, 1.03, 0.966, 0.917, 0.881, 0.854, 0.825, 0.807, 0.781, 0.763, 0.747, 0.731, 0.718, 0.703, 0.689, 0.681, 0.669, 0.663, 0.65, 0.641, 0.634, 0.626],
    [1.72, 1.36, 1.22, 1.11, 1.03, 0.962, 0.919, 0.88, 0.85, 0.819, 0.798, 0.777, 0.762, 0.744, 0.727, 0.715, 0.701, 0.689, 0.676, 0.669, 0.652, 0.647, 0.64, 0.633, 0.627],
    [1.74, 1.37, 1.22, 1.11, 1.02, 0.96, 0.913, 0.876, 0.844, 0.819, 0.797, 0.771, 0.756, 0.737, 0.726, 0.709, 0.693, 0.684, 0.676, 0.661, 0.651, 0.644, 0.639, 0.627, 0.619]
]


# Redefine the latest datasets
loss_data_latest = [
    [1.72, 1.37, 1.21, 1.1, 1.02, 0.954, 0.91, 0.874, 0.845, 0.818, 0.794, 0.772, 0.752, 0.742, 0.72, 0.709, 0.698, 0.684, 0.676, 0.663, 0.651, 0.647, 0.636, 0.628, 0.623],
    [1.06, 0.693, 0.554, 0.458, 0.396, 0.347, 0.307, 0.274, 0.25, 0.226, 0.207, 0.192, 0.176, 0.165, 0.152, 0.139, 0.133, 0.123, 0.11, 0.106, 0.0989, 0.0938, 0.0889, 0.0818, 0.0757],
    [1.85, 1.55, 1.43, 1.33, 1.27, 1.23, 1.19, 1.16, 1.14, 1.12, 1.1, 1.09, 1.07, 1.06, 1.05, 1.04, 1.02, 1.02, 1.01, 1.0, 0.988, 0.985, 0.978, 0.971, 0.966],
    [1.74, 1.38, 1.23, 1.12, 1.03, 0.975, 0.941, 0.903, 0.877, 0.85, 0.833, 0.813, 0.794, 0.781, 0.766, 0.758, 0.744, 0.731, 0.727, 0.715, 0.711, 0.698, 0.684, 0.683],
    #[51.5, 44.3, 40.8, 38.6, 36.9, 35.7, 34.7, 33.9, 33.2, 32.7, 32.1, 31.7, 31.3, 31, 30.6, 30.4, 30.2, 29.9, 29.7, 29.5, 29.4, 29.2, 29.1, 28.9, 28.7]
]

loss_data_final = [
    [1.73, 1.37, 1.21, 1.1, 1.02, 0.955, 0.913, 0.876, 0.848, 0.82, 0.796, 0.775, 0.753, 0.741, 0.722, 0.709, 0.698, 0.685, 0.677, 0.668, 0.65, 0.648, 0.64, 0.629, 0.623],
    [1.74, 1.38, 1.24, 1.12, 1.05, 0.987, 0.942, 0.908, 0.873, 0.845, 0.826, 0.804, 0.785, 0.77, 0.755, 0.743, 0.728, 0.718, 0.705, 0.698, 0.686, 0.675, 0.67, 0.659, 0.653],
    [1.8, 1.45, 1.33, 1.23, 1.15, 1.09, 1.04, 0.999, 0.956, 0.931, 0.906, 0.882, 0.863, 0.844, 0.831, 0.812, 0.802, 0.785, 0.776, 0.766, 0.753, 0.745, 0.729, 0.723, 0.718],
    [1.73, 1.36, 1.19, 1.08, 0.997, 0.936, 0.893, 0.857, 0.825, 0.798, 0.78, 0.761, 0.741, 0.722, 0.707, 0.697, 0.68, 0.674, 0.66, 0.65, 0.642, 0.632, 0.625, 0.615, 0.609]
]

loss_data_latest_set = [
    [1.72, 1.36, 1.22, 1.12, 1.03, 0.969, 0.918, 0.881, 0.839, 0.815, 0.784, 0.762, 0.741, 0.72, 0.7, 0.684, 0.666, 0.651, 0.64, 0.627, 0.618, 0.611, 0.605, 0.602, 0.599],
    [1.74, 1.37, 1.21, 1.1, 1.01, 0.948, 0.899, 0.864, 0.827, 0.801, 0.774, 0.753, 0.73, 0.711, 0.692, 0.677, 0.659, 0.643, 0.63, 0.621, 0.612, 0.602, 0.598, 0.595, 0.594],
    [1.87, 1.52, 1.34, 1.21, 1.11, 1.04, 0.983, 0.933, 0.899, 0.869, 0.835, 0.814, 0.786, 0.765, 0.744, 0.728, 0.711, 0.698, 0.682, 0.671, 0.662, 0.654, 0.647, 0.643, 0.642],
    [2.13, 1.65, 1.41, 1.25, 1.13, 1.04, 0.976, 0.925, 0.884, 0.848, 0.814, 0.784, 0.76, 0.736, 0.714, 0.698, 0.68, 0.665, 0.653, 0.64, 0.633, 0.625, 0.62, 0.618, 0.615],
    [2.08, 1.66, 1.46, 1.33, 1.23, 1.15, 1.08, 1.02, 0.974, 0.938, 0.907, 0.882, 0.861, 0.846, 0.824, 0.812, 0.802, 0.79, 0.781, 0.773, 0.767, 0.764, 0.762, 0.76, 0.761],
    [1.94, 1.6, 1.42, 1.28, 1.17, 1.09, 1.01, 0.957, 0.917, 0.876, 0.847, 0.816, 0.793, 0.769, 0.747, 0.726, 0.711, 0.694, 0.682, 0.669, 0.659, 0.651, 0.645, 0.643, 0.638]
]
# Create a figure
plt.figure(figsize=(10, 6))

# Create the plot for each data set
plt.plot(loss_data_latest_set[0],label = 'Adam 91.95%')
plt.plot(loss_data_latest_set[1],label = 'AdamW 92.36%')
plt.plot(loss_data_latest_set[2],label = 'SGD 91.81%')
plt.plot(loss_data_latest_set[3],label = 'RMSprop 91.71%')
plt.plot(loss_data_latest_set[4],label = 'Adagrad 87.92%')
plt.plot(loss_data_latest_set[5],label = 'Adadelta 91.64%')
#plt.plot(loss_data_latest[4],label = 'CrossEntropy + Auxiliary Loss 90.34%')

# Add labels and title
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Loss Trend Across Models')
plt.legend()

# Display the plot
plt.show()
